<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ashmal Vayani</title>

    <meta name="author" content="Ashmal Vayani">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ashmal Vayani
                </p>
                  <p>
                  <font size="3" style="text-align: justify;"> I am an MSc. student in the College of Engineering and Computer Science department at the <a href="https://www.ucf.edu/" target="_blank"><font size="3">University of Central Florida</a>. I am a member of the <a href="https://www.crcv.ucf.edu/" target="_blank"><font size="3">Center for Research in Computer Vision (CRCV) Lab </a> advised by <a href="https://scholar.google.com/citations?user=p8gsO3gAAAAJ&hl=en" target="_blank"><font size="3">Prof. Mubarak Shah</a>.
                </p>
                <p>
                  <font size="3"> Previously, I was a Research Engineer in the Computer Vision Department, affiliated with the <a href="https://www.ival-mbzuai.com/" target="_blank"><font size="3"> IVAL-Lab </font></a> at <a href="https://mbzuai.ac.ae" target="_blank"><font size="3"> Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)</font></a>.
                  I was advised by <a href="https://sites.google.com/view/fahadkhans/home?pli=1" target="_blank"><font size="3">Prof. Fahad Khan</font></a>, and <a href="https://salman-h-khan.github.io/" target="_blank"><font size="3">Dr. Salman Khan</font></a> (Aug 2023 - Jul 2024). During my undergrad, I worked as a Research Intern at <a href="https://retrocausal.ai/" target="_blank"><font size="3"> Retrocausal </font></a> with <a href="https://retrocausal.ai/authors/zeeshan-zia/" target="_blank"><font size="3">Dr. Zeeshan Zia</font></a>. I completed my Bachelors from <a href="https://www.nu.edu.pk/" target="_blank"><font size="3"> National University of Computer and Emerging Sciences </font></a> majoring in Computer Science (Aug 2019 - June 2023).
                  <br><br>
                </p>
                <p>
                  
                </p>

                </p>
                
                <p style="text-align:center">
                  <a href="mailto:ashmalanis08@gmail.com"> <font size="3">Email</font></a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/drive/folders/1l2-B7vaELW2Q2RTMNjsT46WWxfnuM59H?usp=sharing" target="_blank"> <font size="3">CV</font></a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=K4KF1SwAAAAJ&hl=en" target="_blank"><font size="3">Google Scholar</font></a> &nbsp;/&nbsp;
                  <a href="https://github.com/ashmalvayani" target="_blank"><font size="3">Github</font></a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ashmal-vayani/" target="_blank"><font size="3">LinkedIn</font></a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Ashmal_crop.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Ashmal_crop.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;text-align:justify;"">
                <h2><font size="5" style="font-weight:bold;"> Research Interests</h2>  </font>
                  <font size="3"> I mostly work on Large Language Models, Vision Language Models, Responsible AI, Privacy & Bias, their efficiency, and building downstream industrial applications using RAG methods and LLM deployment.I have also curated high-quality datasets and benchmarks for Multilingual LMMs, Bias Mitigation, and Industrial Applications for the <a href="https://www.worldbank.org/en/region/mena" target="_blank"><font size="3">MENA</font></a> region.
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2 style="font-weight: bold;"><font size="5">News</h2>
              <!-- <ul> -->
                <font size="3"><li>[Aug 2025] - Our work <span style="font-weight: bold; color: purple;"><a href="https://arxiv.org/abs/2503.16423" target="_blank">GAEA</a></span> is accepted at <strong>WACV 2026</strong>.</li>
                <font size="3"><li>[Aug 2025] - Our work <span style="font-weight: bold; color: purple;"><a href="https://arxiv.org/pdf/2506.07032" target="_blank">VIMUL</a></span> is accepted at <strong>EMNLP 2025</strong>.</li>
                <font size="3"><li>[Aug 2025] - Our work <span style="font-weight: bold; color: purple;"> <a href="https://arxiv.org/pdf/2508.03199" target="_blank">GRAMVIS</a></span> is accepted at <strong>EMNLP Findings 2025</strong> .</li>
                <font size="3"><li>[Jun 2025] - Co-organized CVPR 2025 Workshop for <span style="font-weight: bold; color: purple;"></span> <a href="https://www.crcv.ucf.edu/cvpr2025-vidllms-workshop/index.html" target="_blank"</li><font size="3">VidLLMs.</a>
                <font size="3"><li>[May 2025] - Started internship at <span style="font-weight: bold; color: purple;">Pinterest</span> as an MLE Intern in the Visual Search Team.</li>
                <font size="3"><li>[Mar 2025] - Our work <span style="font-weight: bold; color: purple;"><a href="https://arxiv.org/pdf/2402.16840" target="_blank">MobiLlama</a></span> is accepted at <strong>ICLR-SLLM Workshop 2025</strong> (Spotlight).</li>
                <font size="3"><li>[Feb 2025] - Our work <span style="font-weight: bold; color: purple;"><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Vayani_All_Languages_Matter_Evaluating_LMMs_on_Culturally_Diverse_100_Languages_CVPR_2025_paper.pdf" target="_blank">ALM-Bench</a></span> is accepted at <strong>CVPR 2025 (Highlight)</strong>.</li>
                <font size="3"><li>[Oct 2024] - Our work <span style="font-weight: bold; color: purple;"><a href="https://arxiv.org/pdf/2403.14743" target="_blank">VURF</a></span> is accepted at <a href="https://neurips.cc/virtual/2024/workshop/84735" target="_blank"</li><font size="3">NeurIPS VLM Workshop, 2024.</a>
                <font size="3"><li>[Aug 2024] - Joined the <a href="https://www.crcv.ucf.edu/people/students/ms-students/" target="_blank"><font size="3">UCF (CRCV)</a> as a Master's in Computer Vision Student.</li>
                <font size="3"><li>[Jan 2024] - Promoted to a Research Engineer at <a href="https://www.ival-mbzuai.com/about" target="_blank"><font size="3">MBZUAI</a>.</li>
                <font size="3"><li>[Dec 2023] - Merit Award - Tertiary Student Project <a href="https://apicta.org/past-winners/apicta-2023/" target="_blank"><font size="3">APICTA Awards</a> held in Hong Kong 2023.</li>
                <font size="3"><li>[Dec 2023] - People's Choice Award at <a href="https://www.youtube.com/watch?v=dJuNvKRJAbI&ab_channel=APICTAAsiaPacific" target="_blank"><font size="3">APICTA Awards</a> held in Hong Kong 2023.</li>
                <font size="3"><li>[Nov 2023] - Released the <a href="https://mbzuai.ac.ae/news/jais-climate-mbzuai-and-core-42-launch-first-bilingual-llm-dedicated-to-climate-intelligence/" target="_blank"><font size="3">Jais Climate</a> as a Lead Engineer.</li>
                <font size="3"><li>[Aug 2023] - Joined the <a href="https://www.ival-mbzuai.com/about" target="_blank"><font size="3">MBZUAI</a> as a Research Assistant.</li>
                  
            </td>
          </tr>
        </tbody></table>
          


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2 style="font-weight: bold;"><font size="5"> Publications</h2> </font>
                <p><font size="3"> selected publications, full <a href="https://scholar.google.com/citations?user=K4KF1SwAAAAJ&hl=en&oi=ao" target="_blank"><font size="3">here</a></p>  
                <p>* <font size="3"> denotes joint first authors</p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/ALM-Bench.jpg" alt="VURF-diag" width="220" height="130">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages</span>
            </a>
            <br>
            <strong><font size="3">Ashmal Vayani</font></strong>,
            <font size="3">Dinura Dissanayake</font>,
            <font size="3">Hasindri Watawana</font>,
            <font size="3">Omkar Thawakar</font>,
<!--             <font size="3">Aman Chadha,</font>, -->
<!--             <font size="3">Hisham Cholakkal</font>,
            <font size="3">Rao Muhammad Anwer</font>, -->
            <font size="3">Michael Felsberg</font>,
            <font size="3">Thamar Solorio</font>,
            <font size="3">Monojit Choudhury</font>,
            <font size="3">Ivan Laptev</font>,
            <font size="3">Mubarak Shah</font>,
            <font size="3">Salman Khan</font></a>,
            <font size="3">Fahad Shahbaz Khan</font></a>
            <br>
            <em><font size="3"><span style="color:purple">CVPR 2025 (Highlight)</span></em>
            <br>
            <a href="https://arxiv.org/abs/2411.16508" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://mbzuai-oryx.github.io/ALM-Bench/" target="_blank"><font size="3">Project</font></a>
            /
            <a href="https://github.com/mbzuai-oryx/ALM-Bench" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/datasets/MBZUAI/ALM-Bench" target="_blank"><font size="3">Data</font></a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/GAEA.png" alt="GAEA-Figure" width="220" height="180">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">GAEA: A Geolocation Aware Conversational Assistant</span>
            </a>
            <br>
            <font size="3">Ron Campos*</font>,
            <strong><font size="3">Ashmal Vayani*</font></strong>,
            <font size="3">Parth Parag Kulkarni*</font>,
            <font size="3">Rohit Gupta</font>
            <font size="3">Aizan Zafar</font>,
            <font size="3">Aritra Dutta</font>,
            <font size="3">Mubarak Shah</font>,
            <br>
            <em><font size="3"><span style="color:purple">WACV 2026</span></em>
            <br>
            <a href="https://arxiv.org/abs/2503.16423" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://ucf-crcv.github.io/GAEA/" target="_blank"><font size="3">Project</font></a>
            /
            <a href="https://github.com/UCF-CRCV/GAEA" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/collections/ucf-crcv/gaea-67d514a61d48eb1708b13a08" target="_blank"><font size="3">Data</font></a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/VIMUL.png" alt="ViMUL-Figure" width="220" height="180">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">A Culturally-diverse Multilingual Multimodal Video Benchmark & Model</span>
            </a>
            <br>
            <font size="3">Bhuiyan Sanjid Shafique</font>,
            <strong><font size="3">Ashmal Vayani</font></strong>,
            <font size="3">Muhammad Maaz</font>,
            <font size="3">Hanoona Abdul Rasheed</font>,
            <font size="3">Dinura Dissanayake</font>
            <font size="3">Michael Felsberg</font>,
            <font size="3">Mubarak Shah</font>,
            <font size="3">Salman Khan</font>
            <font size="3">Fahad Shahbaz Khan</font>
            <br>
            <em><font size="3"><span style="color:purple">EMNLP 2025 (Main)</span></em>
            <br>
            <a href="https://arxiv.org/pdf/2506.07032" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://mbzuai-oryx.github.io/ViMUL" target="_blank"><font size="3">Project</font></a>
            /
            <a href="https://github.com/mbzuai-oryx/ViMUL" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/datasets/MBZUAI/ViMUL-Bench" target="_blank"><font size="3">Data</font></a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/GRAMVIS.png" alt="GRAMVIS-Visual" width="220" height="180">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models</span>
            </a>
            <br>
            <font size="3">Muhammed Saeed</font>,
            <font size="3">Shaina Raza</font>,
            <strong><font size="3">Ashmal Vayani</font></strong>,
            <font size="3">Muhammad Abdul-Mageed</font>,
            <font size="3">Ali Emami</font>,
            <font size="3">Shady Shehata</font>
            <br>
            <em><font size="3"><span style="color:purple">EMNLP 2025 (Findings)</span></em>
            <br>
            <a href="https://arxiv.org/pdf/2508.03199?" target="_blank"><font size="3">Paper</font></a>
<!--             /
            <a href="https://mbzuai-oryx.github.io/ViMUL" target="_blank"><font size="3">Project</font></a>
            /
            <a href="https://github.com/mbzuai-oryx/ViMUL" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/datasets/MBZUAI/ViMUL-Bench" target="_blank"><font size="3">Data</font></a> -->
            <p></p>
          </td>
        </tr>
            
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/VURF.png" alt="VURF-diag" width="220" height="130">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">VURF: A General-purpose Reasoning and Self-refinement Framework for Video Understanding</span>
            </a>
            <br>
            <strong><font size="3">Ashmal Vayani*</font></strong>,
            <font size="3">Ahmad Mahmood*</font>,
            <font size="3">Muzammal Naseer</font>,
            <font size="3">Salman Khan</font></a>,
            <font size="3">Fahad Shahbaz Khan</font></a>
            <br>
            <em><font size="3"><span style="color:purple">NeurIPS Vision Language Models Workshop 2024.</span></em>
            <br>
            <a href="https://arxiv.org/pdf/2403.14743" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://github.com/ahmad-573/VURF" target="_blank"><font size="3">Code</font></a>
            <p></p>
          </td>
        </tr>
            
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/Mobillama.png" alt="Mobillama-diag" width="220" height="130">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT</span>
            </a>
            <br>

            <font size="3">Omkar Thawakar*</font></a>,
            <strong><font size="3">Ashmal Vayani*</font></strong>,
            <font size="3">Salman Khan</font></a>,
            <font size="3">Hisham Cholakkal</font></a>,
            <font size="3">Rao Muhammad Anwer</font></a>,
            <font size="3">Michael Felsberg</font></a>,
            <font size="3">Timothy Baldwin</font></a>,
            <font size="3">Eric P. Xing</font></a>,
            <font size="3">Fahad Shahbaz Khan</font></a>
            <br>
            <em><font size="3"><span style="color:purple">ICLR SLLM Workshop 2025 (Spotight)</span></em>
            <br>
            <a href="https://arxiv.org/pdf/2402.16840" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://github.com/mbzuai-oryx/MobiLlama" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/collections/MBZUAI/mobillama-65dd4182d588c91e8230332e" target="_blank"><font size="3">Models</font></a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle;">
            <img src="images/SB-Bench.JPG" alt="SB-Bench-Figure" width="220" height="180">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify;">
            </a>
              <span class="papertitle"><font size="3">SB-Bench: <u>S</u>stereotype <u>B</u>ias <u>Bench</u>mark for Large Multimodal Models</span>
            </a>
            <br>
            <font size="3">Vishal Narnaware*</font>,
            <strong><font size="3">Ashmal Vayani*</font></strong>,
            <font size="3">Rohit Gupta</font>,
            <font size="3">Swetha Sirnam</font>,
            <font size="3">Mubarak Shah</font>
            <br>
            <em><font size="3">Under Review</em>
            <br>
            <a href="https://arxiv.org/pdf/2502.08779" target="_blank"><font size="3">Paper</font></a>
            /
            <a href="https://ucf-crcv.github.io/SB-Bench/" target="_blank"><font size="3">Project</font></a>
            /
            <a href="https://github.com/UCF-CRCV/SB-Bench" target="_blank"><font size="3">Code</font></a>
            /
            <a href="https://huggingface.co/datasets/ucf-crcv/SB-Bench" target="_blank"><font size="3">Data</font></a>
            <p></p>
          </td>
        </tr>


    </tbody>
  </table>
</tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:0px">
                <br>
                <!-- <p style="text-align:center;font-size:small;">
                  Source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>. 
                </p> -->
            </td>
        </tr>
    </tbody></table>
        
        </td>
      </tr>
    </table>
  </body>
</html>
